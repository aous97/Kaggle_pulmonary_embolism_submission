{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('../input/rsna-str-pulmonary-embolism-detection/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm as tqdm\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import albumentations\n",
    "\n",
    "import pydicom\n",
    "import os, os.path as osp\n",
    "\n",
    "\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.43216, 0.394666, 0.37645],\n",
    "                            std=[0.22803, 0.22145, 0.216989])\n",
    "])\n",
    "Transform = transforms.Compose([\n",
    "      transforms.ToTensor()\n",
    "])\n",
    "trans1 = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans1 = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_array(dicom_files):\n",
    "    dicom_files = glob(osp.join(dicom_files, '*.dcm'))\n",
    "    dicoms = [pydicom.dcmread(d) for d in dicom_files]\n",
    "    # Assume all images are axial\n",
    "    z_pos = [float(d.ImagePositionPatient[-1]) for d in dicoms]\n",
    "    return np.asarray(dicom_files)[np.argsort(z_pos)]\n",
    "\n",
    "def edit_filenames(files):\n",
    "    dicoms = [f\"{ind:04d}_{f.split('/')[-1]}\" for ind,f in enumerate(files)]\n",
    "    series = ['/'.join(f.split('/')[-3:-1]) for f in files]\n",
    "    return [osp.join(s,d) for s,d in zip(series, dicoms)]\n",
    "\n",
    "\n",
    "class Lungs(Dataset):\n",
    "    def __init__(self, dicom_folders):\n",
    "        self.dicom_folders = dicom_folders\n",
    "    def __len__(self): return len(self.dicom_folders)\n",
    "    def get(self, i):\n",
    "        return load_dicom_array(self.dicom_folders[i])\n",
    "    def __getitem__(self, i):\n",
    "        try:\n",
    "            return self.get(i)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "\n",
    "MAX_LENGTH = 256.\n",
    "\n",
    "df = pd.read_csv('../input/rsna-str-pulmonary-embolism-detection/test.csv')\n",
    "dicom_folders = list(('../input/rsna-str-pulmonary-embolism-detection/test' + df.StudyInstanceUID + '/'+ df.SeriesInstanceUID + '/').unique())\n",
    "dset = Lungs(dicom_folders)\n",
    "loader = DataLoader(dset, batch_size=1, shuffle=False, num_workers=0, collate_fn=lambda x: x)\n",
    "df['path'] = df['SOPInstanceUID']\n",
    "df['position'] = df['StudyInstanceUID']\n",
    "positions = dict(zip(df['SOPInstanceUID'], df.index))\n",
    "\n",
    "for data in tqdm(loader, total=len(loader)):\n",
    "    data = data[0]\n",
    "    if type(data) == type(None):\n",
    "        continue\n",
    "    try:\n",
    "        files = data\n",
    "        files = edit_filenames(files)\n",
    "        for i in range(len(files)):\n",
    "            SOP = files[i].split('/')[2].split('.')[0].split('_')[1]\n",
    "            idx = positions[SOP]\n",
    "            df.at[idx, 'path'] = data[i]\n",
    "            df.at[idx, 'position'] = files[i]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "df = df.sort_values('position').reset_index().drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_resolution_CT(inpt_exam, outpt_size):\n",
    "    if len(inpt_exam) < outpt_size:\n",
    "        return(inpt_exam)\n",
    "    result = pd.DataFrame(columns = inpt_exam.columns)\n",
    "    temp = inpt_exam.reset_index().drop(['index'], axis = 1)\n",
    "    fact = int((len(inpt_exam)*10/outpt_size))\n",
    "    rm_count = fact - 10\n",
    "    #remove rm_count element from every fact batch\n",
    "    step = int(len(inpt_exam)/fact)\n",
    "    for i in range(step):\n",
    "        batch_t = temp[temp.index <= (i + 1)*fact]\n",
    "        batch = batch_t[batch_t.index > i*fact]\n",
    "        #rm_batch = batch[batch.pe_present_on_image == 0]\n",
    "        rm_batch = batch\n",
    "        if len(rm_batch) >= rm_count:\n",
    "            rm_idx = random.sample(list(rm_batch.index), rm_count)\n",
    "            batch.drop(rm_idx, axis = 0, inplace = True)\n",
    "            #print(rm_idx)\n",
    "        else:\n",
    "            batch.drop(rm_batch.index, axis = 0, inplace = True)\n",
    "            rm_idx = random.sample(list(batch.index), rm_count - len(rm_batch))\n",
    "            batch.drop(rm_idx, axis = 0, inplace = True)\n",
    "            #print(rm_idx)\n",
    "        result = pd.concat([result, batch]).reset_index().drop(['index'], axis = 1)\n",
    "    if len(result) == outpt_size -1:\n",
    "        result = pd.concat([result, result[len(result)-1:]]).reset_index().drop(['index'], axis = 1)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_slices(inpt_exam, window_size):\n",
    "    temp = inpt_exam.copy().reset_index().drop(['index'], axis=1)\n",
    "    temp['slice'] = inpt_exam['SOPInstanceUID']\n",
    "    step_num = int(len(inpt_exam)/window_size)\n",
    "    idx = 0\n",
    "    for i in range(step_num):\n",
    "        instance = temp['SOPInstanceUID'][i*window_size]\n",
    "        for j in range(window_size):\n",
    "            idx = i*window_size + j\n",
    "            temp['slice'][idx] = instance\n",
    "    if idx < len(inpt_exam)-1:\n",
    "        idx += 1\n",
    "        instance = temp['SOPInstanceUID'][idx]\n",
    "        temp['slice'][idx] = instance\n",
    "        for j in range(len(inpt_exam) - idx):\n",
    "            idx += 1\n",
    "            temp['slice'][idx] = instance\n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_3D(table, max_resol, window_size):\n",
    "    Exams = list(table['StudyInstanceUID'].unique())\n",
    "    #reduce resolution\n",
    "    l_res = pd.DataFrame(columns = table.columns)\n",
    "    l_res['slice'] = l_res['SOPInstanceUID']\n",
    "    for i, Exam in tqdm(enumerate(Exams)):\n",
    "        temp = table[table.StudyInstanceUID == Exam]\n",
    "        temp = reduce_resolution_CT(temp, max_resol)\n",
    "        #distinguish slices\n",
    "        temp = distinct_slices(temp, window_size)\n",
    "        l_res = pd.concat([l_res, temp])\n",
    "    l_res = l_res.reset_index().drop(['index'], axis = 1)\n",
    "    return(l_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tij = table_3D(df, max_resol = 192, window_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_detect(net):\n",
    "    big_detect_net = net\n",
    "    big_detect_net.load_state_dict(torch.load('../input/mymodels/best_bigdetect.pth'))\n",
    "    big_detect_net = big_detect_net.eval()\n",
    "    #fscore 50% (good recall)\n",
    "    return(big_detect_net.cuda())\n",
    "def load_right(net):\n",
    "    right_det_net = net\n",
    "    right_det_net.load_state_dict(torch.load('../input/mymodels/PEright_45_49.pth'))\n",
    "    right_det_net = right_det_net.eval()\n",
    "    #detection: 45% + right: 49%\n",
    "    return(right_det_net.cuda())\n",
    "def load_left(net):\n",
    "    left_net = net\n",
    "    left_net.load_state_dict(torch.load('../input/mymodels/best_left.pth'))\n",
    "    left_net = left_net.eval()\n",
    "    #fscore 48% acc 91%\n",
    "    return(left_net.cuda())\n",
    "def load_central(net):\n",
    "    central_net = net\n",
    "    central_net.load_state_dict(torch.load('../input/mymodels/best_central.pth'))\n",
    "    central_net = central_net.eval()\n",
    "    #fscore 57%\n",
    "    return(central_net.cuda())\n",
    "models = {'big_detect_net': load_detect, 'right_det_net': load_right,\n",
    "          'left_net': load_left, 'central_net': load_central}\n",
    "modelslist = ['big_detect_net', 'right_det_net', 'left_net', 'central_net']\n",
    "C = {'big_detect_net': ['negative_detect', 'positive_detect'], 'right_det_net' : ['right_detect', 'right'],\n",
    "    'left_net': ['negative_left', 'positive_left'], 'central_net': ['negative_central', 'positive_central']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_pipeline(tab):\n",
    "    eval_tab = pd.DataFrame(columns = ['Exam', 'slice', 'negative_detect', 'positive_detect', \n",
    "                                      'right_detect', 'right', 'negative_left', 'positive_left',\n",
    "                                      'negative_central', 'positive_central', 'negative_chronic','chronic',\n",
    "                                     'acute', 'qa_motion', 'qa_contrast', 'flow_artifact', 'true_filling_defect_not_pe'])\n",
    "    Exams = tab['StudyInstanceUID'].dropna().unique()\n",
    "    for i, exam in tqdm(enumerate(Exams)):\n",
    "        B1 = [0]*17\n",
    "        B2 = [0]*17\n",
    "        B3 = [0]*17\n",
    "        B4 = [0]*17\n",
    "        ex = tab[tab.StudyInstanceUID == exam].reset_index().drop(['index'], axis = 1)\n",
    "        slices = ex['slice'].dropna().unique()\n",
    "        B1[0] = exam\n",
    "        B2[0] = exam\n",
    "        B3[0] = exam\n",
    "        B4[0] = exam\n",
    "        B1[1] = slices[0]\n",
    "        B2[1] = slices[1]\n",
    "        try:\n",
    "            B3[1] = slices[2]\n",
    "        except:\n",
    "            B3[1] = 'noslice'\n",
    "        try:\n",
    "            B4[1] = slices[3]\n",
    "        except:\n",
    "            B4[1] = 'noslice'\n",
    "        \n",
    "        B1 = pd.DataFrame([B1], columns= eval_tab.columns)\n",
    "        B2 = pd.DataFrame([B2], columns= eval_tab.columns)\n",
    "        B3 = pd.DataFrame([B3], columns= eval_tab.columns)\n",
    "        B4 = pd.DataFrame([B4], columns= eval_tab.columns)\n",
    "        \n",
    "        eval_tab = pd.concat([eval_tab, B1, B2, B3, B4])\n",
    "    return(eval_tab.reset_index().drop(['index'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tab = empty_pipeline(tij)\n",
    "for col in eval_tab.columns[2:14]:\n",
    "    eval_tab[col] = pd.to_numeric(eval_tab[col], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "def load_dicom_array(dicom_files):\n",
    "    dicoms = [pydicom.dcmread(d) for d in dicom_files]\n",
    "    M = float(dicoms[0].RescaleSlope)\n",
    "    B = float(dicoms[0].RescaleIntercept)\n",
    "    # Assume all images are axial\n",
    "    z_pos = [float(d.ImagePositionPatient[-1]) for d in dicoms]\n",
    "    dicoms = np.asarray([d.pixel_array for d in dicoms])\n",
    "    dicoms = dicoms[np.argsort(z_pos)]\n",
    "    dicoms = dicoms * M\n",
    "    dicoms = dicoms + B\n",
    "    return dicoms, np.asarray(dicom_files)[np.argsort(z_pos)]\n",
    "\n",
    "def window(img, WL=50, WW=350):\n",
    "    upper, lower = WL+WW//2, WL-WW//2\n",
    "    X = np.clip(img.copy(), lower, upper)\n",
    "    X = X - np.min(X)\n",
    "    X = X / np.max(X)\n",
    "    X = (X*255.0).astype('uint8')\n",
    "    return X\n",
    "\n",
    "def read_image(dicom_files, image_size=256):\n",
    "    image, files = load_dicom_array(dicom_files)\n",
    "    # Windows from https://pubs.rsna.org/doi/pdf/10.1148/rg.245045008\n",
    "    image_lung = np.expand_dims(window(image, WL=-600, WW=1500), axis=3)\n",
    "    image_mediastinal = np.expand_dims(window(image, WL=40, WW=400), axis=3)\n",
    "    image_pe_specific = np.expand_dims(window(image, WL=100, WW=700), axis=3)\n",
    "    image = np.concatenate([image_lung, image_pe_specific, image_mediastinal], axis=3)\n",
    "    rat = image_size / np.max(image.shape[1:])\n",
    "    image = zoom(image, [1.,rat,rat, 1.], prefilter=False, order=1)\n",
    "    image = Transform(image[0])\n",
    "    return image\n",
    "\n",
    "def read_dicom(dicom_files, image_size=256):\n",
    "    image, files = load_dicom_array(dicom_files)\n",
    "    # Windows from https://pubs.rsna.org/doi/pdf/10.1148/rg.245045008\n",
    "    image_lung = np.expand_dims(window(image, WL=-600, WW=1500), axis=3)\n",
    "    image_mediastinal = np.expand_dims(window(image, WL=40, WW=400), axis=3)\n",
    "    image_pe_specific = np.expand_dims(window(image, WL=100, WW=700), axis=3)\n",
    "    image = np.concatenate([image_lung, image_pe_specific, image_mediastinal], axis=3)\n",
    "    rat = image_size / np.max(image.shape[1:])\n",
    "    image = zoom(image, [1., rat,rat, 1.], prefilter=False, order=1)\n",
    "    image = transform(image[0]).unsqueeze(0)\n",
    "    output = torch.zeros((3,48,256,256))\n",
    "    output[:,:image.size(1), :, :] = image\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_image(['../input/rsna-str-pulmonary-embolism-detection/test/00268ff88746/75d23269adbd/012c12fe09c3.dcm']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PE_dataset_pipeline(torch.utils.data.Dataset):\n",
    "    def __init__(self, eval_tab, tab, window = 48):\n",
    "        self.slices = list(eval_tab['slice'].unique())\n",
    "        self.slices.remove('noslice')\n",
    "        self.window = window\n",
    "        self.Table = eval_tab\n",
    "        self.tab = tab\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        mini_batch = self.Table[self.Table.slice == self.slices[index]]\n",
    "        mb = self.tab[self.tab.slice == self.slices[index]]\n",
    "        Input = read_dicom(mb['path'])\n",
    "        return([Input, mini_batch.index[0]])\n",
    "    def __len__(self):\n",
    "        return(len(self.slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation Block.\n",
    "\n",
    "    Based on the paper:\n",
    "    \"Squeeze-and-Excitation Networks\"\n",
    "    by Jie Hu, Li Shen, Gang Sun\n",
    "    (https://arxiv.org/abs/1709.01507).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool3d(1)\n",
    "        self.excite = nn.Sequential(nn.Linear(num_channels, num_channels // reduction),\n",
    "                                    nn.LeakyReLU(inplace=True),\n",
    "                                    nn.Linear(num_channels // reduction, num_channels),\n",
    "                                    nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        num_channels = x.size(1)\n",
    "\n",
    "        # Squeeze\n",
    "        z = self.squeeze(x)\n",
    "        z = z.view(-1, num_channels)\n",
    "\n",
    "        # Excite\n",
    "        s = self.excite(z)\n",
    "        s = s.view(-1, num_channels, 1, 1, 1)\n",
    "\n",
    "        # Apply gate\n",
    "        x = x * s\n",
    "\n",
    "        return x\n",
    "\n",
    "class PENetLateral(nn.Module):\n",
    "    \"\"\"Lateral connection layer for PENet.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PENetLateral, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.norm = nn.GroupNorm(out_channels // 16, out_channels)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x, x_skip):\n",
    "        # Reduce number of channels in skip connection\n",
    "        x_skip = self.conv(x_skip)\n",
    "        x_skip = self.norm(x_skip)\n",
    "        x_skip = self.relu(x_skip)\n",
    "\n",
    "        # Add reduced feature map\n",
    "        x += x_skip\n",
    "\n",
    "        return x\n",
    "\n",
    "class PENetDecoder(nn.Module):\n",
    "    \"\"\"Decoder (up-sampling layer) for PENet\"\"\"\n",
    "    def __init__(self, skip_channels, in_channels, mid_channels, out_channels, kernel_size=4, stride=2):\n",
    "        super(PENetDecoder, self).__init__()\n",
    "\n",
    "        if skip_channels > 0:\n",
    "            self.lateral = PENetLateral(skip_channels, in_channels)\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.norm1 = nn.GroupNorm(mid_channels // 16, mid_channels)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose3d(mid_channels, mid_channels, kernel_size=kernel_size, stride=stride, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(mid_channels // 16, mid_channels)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv3d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.norm3 = nn.GroupNorm(out_channels // 16, out_channels)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x, x_skip=None):\n",
    "        if x_skip is not None:\n",
    "            x = self.lateral(x, x_skip)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class PENetASPPool(nn.Module):\n",
    "    \"\"\"Atrous Spatial Pyramid Pooling layer.\n",
    "\n",
    "    Based on the paper:\n",
    "    \"Rethinking Atrous Convolution for Semantic Image Segmentation\"\n",
    "    by Liang-Chieh Chen, George Papandreou, Florian Schroff, Hartwig Adam\n",
    "    (https://arxiv.org/abs/1706.05587).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PENetASPPool, self).__init__()\n",
    "\n",
    "        self.mid_channels = out_channels // 4\n",
    "        self.in_conv = nn.Sequential(nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=2, dilation=2),\n",
    "                                     nn.GroupNorm(out_channels // 16, out_channels),\n",
    "                                     nn.LeakyReLU(inplace=True))\n",
    "\n",
    "        self.conv1 = nn.Conv3d(out_channels, self.mid_channels, kernel_size=1)\n",
    "        self.conv2 = nn.Conv3d(out_channels, self.mid_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3 = nn.Conv3d(out_channels, self.mid_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.conv4 = nn.Sequential(nn.AdaptiveAvgPool3d(1),\n",
    "                                   nn.Conv3d(out_channels, self.mid_channels, kernel_size=1))\n",
    "        self.norm = nn.GroupNorm(out_channels // 16, out_channels)\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "        self.out_conv = nn.Sequential(nn.Conv3d(out_channels, out_channels, kernel_size=1),\n",
    "                                      nn.GroupNorm(out_channels // 16, out_channels),\n",
    "                                      nn.LeakyReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_conv(x)\n",
    "\n",
    "        # Four parallel paths with different dilation factors\n",
    "        x_1 = self.conv1(x)\n",
    "        x_2 = self.conv2(x)\n",
    "        x_3 = self.conv3(x)\n",
    "        x_4 = self.conv4(x)\n",
    "        x_4 = x_4.expand(-1, -1, x_1.size(2), x_1.size(3), x_1.size(4))\n",
    "\n",
    "        # Combine parallel pathways\n",
    "        x = torch.cat((x_1, x_2, x_3, x_4), dim=1)\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.out_conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class GAPLinear(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"Global average pooling (3D) followed by a linear layer.\n",
    "\n",
    "        Args:\n",
    "            in_channels: Number of input channels.\n",
    "            out_channels: Number of output channels\n",
    "        \"\"\"\n",
    "        super(GAPLinear, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Linear(in_channels, out_channels)\n",
    "        self.fc.is_output_head = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class PENetBottleneck(nn.Module):\n",
    "    \"\"\"PENet bottleneck block, similar to a pre-activation ResNeXt bottleneck block.\n",
    "\n",
    "    Based on the paper:\n",
    "    \"Aggregated Residual Transformations for Deep Nerual Networks\"\n",
    "    by Saining Xie, Ross Girshick, Piotr DollÃ¡r, Zhuowen Tu, Kaiming He\n",
    "    (https://arxiv.org/abs/1611.05431).\n",
    "    \"\"\"\n",
    "\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, in_channels, channels, block_idx, total_blocks, cardinality=32, stride=1):\n",
    "        super(PENetBottleneck, self).__init__()\n",
    "        mid_channels = cardinality * int(channels / cardinality)\n",
    "        out_channels = channels * self.expansion\n",
    "        self.survival_prob = self._get_survival_prob(block_idx, total_blocks)\n",
    "\n",
    "        self.down_sample = None\n",
    "        if stride != 1 or in_channels != channels * PENetBottleneck.expansion:\n",
    "            self.down_sample = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, channels * PENetBottleneck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.GroupNorm(channels * PENetBottleneck.expansion // 16, channels * PENetBottleneck.expansion))\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, mid_channels, kernel_size=1, bias=False)\n",
    "        self.norm1 = nn.GroupNorm(mid_channels // 16, mid_channels)\n",
    "        self.relu1 = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(mid_channels, mid_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=cardinality, bias=False)\n",
    "        self.norm2 = nn.GroupNorm(mid_channels // 16, mid_channels)\n",
    "        self.relu2 = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv3d(mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.norm3 = nn.GroupNorm(out_channels // 16, out_channels)\n",
    "        self.norm3.is_last_norm = True\n",
    "        self.relu3 = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "        self.se_block = SEBlock(out_channels, reduction=16)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_survival_prob(block_idx, total_blocks, p_final=0.5):\n",
    "        \"\"\"Get survival probability for stochastic depth. Uses linearly decreasing\n",
    "        survival probability as described in \"Deep Networks with Stochastic Depth\".\n",
    "\n",
    "        Args:\n",
    "            block_idx: Index of residual block within entire network.\n",
    "            total_blocks: Total number of residual blocks in entire network.\n",
    "            p_final: Survival probability of the final layer.\n",
    "        \"\"\"\n",
    "        return 1. - block_idx / total_blocks * (1. - p_final)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_skip = x if self.down_sample is None else self.down_sample(x)\n",
    "\n",
    "        # Stochastic depth dropout\n",
    "        if self.training and random.random() > self.survival_prob:\n",
    "            return x_skip\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "\n",
    "        x = self.se_block(x)\n",
    "        x += x_skip\n",
    "\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class PENetEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, channels, num_blocks, cardinality, block_idx, total_blocks, stride=1):\n",
    "        super(PENetEncoder, self).__init__()\n",
    "\n",
    "        # Get PENet blocks\n",
    "        penet_blocks = [PENetBottleneck(in_channels, channels, block_idx, total_blocks, cardinality, stride)]\n",
    "\n",
    "        for i in range(1, num_blocks):\n",
    "            penet_blocks += [PENetBottleneck(channels * PENetBottleneck.expansion, channels,\n",
    "                                           block_idx + i, total_blocks, cardinality)]\n",
    "        self.penet_blocks = nn.Sequential(*penet_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.penet_blocks(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class PENetClassifier(nn.Module):\n",
    "    \"\"\"PENet stripped down for classification.\n",
    "\n",
    "    The idea is to pre-train this network, then use the pre-trained\n",
    "    weights for the encoder in a full PENet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_depth, cardinality=32, num_channels=3, num_classes=600, init_method=None, **kwargs):\n",
    "        super(PENetClassifier, self).__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "        self.model_depth = model_depth\n",
    "        self.cardinality = cardinality\n",
    "        self.num_channels = num_channels\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.in_conv = nn.Sequential(nn.Conv3d(self.num_channels, self.in_channels, kernel_size=7,\n",
    "                                               stride=(1, 2, 2), padding=(3, 3, 3), bias=False),\n",
    "                                     nn.GroupNorm(self.in_channels // 16, self.in_channels),\n",
    "                                     nn.LeakyReLU(inplace=True))\n",
    "        self.max_pool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "\n",
    "        # Encoders\n",
    "        if model_depth != 50:\n",
    "            raise ValueError('Unsupported model depth: {}'.format(model_depth))\n",
    "        encoder_config = [3, 4, 6, 3]\n",
    "        total_blocks = sum(encoder_config)\n",
    "        block_idx = 0\n",
    "\n",
    "        self.encoders = nn.ModuleList()\n",
    "        for i, num_blocks in enumerate(encoder_config):\n",
    "            out_channels = 2 ** i * 128\n",
    "            stride = 1 if i == 0 else 2\n",
    "            encoder = PENetEncoder(self.in_channels, out_channels, num_blocks, self.cardinality,\n",
    "                                  block_idx, total_blocks, stride=stride)\n",
    "            self.encoders.append(encoder)\n",
    "            self.in_channels = out_channels * PENetBottleneck.expansion\n",
    "            block_idx += num_blocks\n",
    "\n",
    "        self.classifier = GAPLinear(self.in_channels, num_classes)\n",
    "\n",
    "        if init_method is not None:\n",
    "            self._initialize_weights(init_method, focal_pi=0.01)\n",
    "\n",
    "    def _initialize_weights(self, init_method, gain=0.2, focal_pi=None):\n",
    "        \"\"\"Initialize all weights in the network.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose3d) or isinstance(m, nn.Linear):\n",
    "                if init_method == 'normal':\n",
    "                    nn.init.normal_(m.weight, mean=0, std=gain)\n",
    "                elif init_method == 'xavier':\n",
    "                    nn.init.xavier_normal_(m.weight, gain=gain)\n",
    "                elif init_method == 'kaiming':\n",
    "                    nn.init.kaiming_normal_(m.weight)\n",
    "                else:\n",
    "                    raise NotImplementedError('Invalid initialization method: {}'.format(self.init_method))\n",
    "                if hasattr(m, 'bias') and m.bias is not None:\n",
    "                    if focal_pi is not None and hasattr(m, 'is_output_head') and m.is_output_head:\n",
    "                        # Focal loss prior (~0.01 prob for positive, see RetinaNet Section 4.1)\n",
    "                        nn.init.constant_(m.bias, -math.log((1 - focal_pi) / focal_pi))\n",
    "                    else:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.GroupNorm) and m.affine:\n",
    "                # Gamma for last GroupNorm in each residual block gets set to 0\n",
    "                init_gamma = 0 if hasattr(m, 'is_last_norm') and m.is_last_norm else 1\n",
    "                nn.init.constant_(m.weight, init_gamma)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Expand input (allows pre-training on RGB videos, fine-tuning on Hounsfield Units)\n",
    "        if x.size(1) < self.num_channels:\n",
    "            x = x.expand(-1, self.num_channels // x.size(1), -1, -1, -1)\n",
    "\n",
    "        x = self.in_conv(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        # Encoders\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "\n",
    "        # Classifier\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def args_dict(self):\n",
    "        \"\"\"Get a dictionary of args that can be used to reconstruct this architecture.\n",
    "        To use the returned dict, initialize the model with `PENet(**model_args)`.\n",
    "        \"\"\"\n",
    "        model_args = {\n",
    "            'model_depth': self.model_depth,\n",
    "            'cardinality': self.cardinality,\n",
    "            'num_classes': self.num_classes,\n",
    "            'num_channels': self.num_channels\n",
    "        }\n",
    "\n",
    "        return model_args\n",
    "\n",
    "    def load_pretrained(self, ckpt_path, gpu_ids):\n",
    "        \"\"\"Load parameters from a pre-trained PENetClassifier from checkpoint at ckpt_path.\n",
    "        Args:\n",
    "            ckpt_path: Path to checkpoint for PENetClassifier.\n",
    "        Adapted from:\n",
    "            https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113/2\n",
    "        \"\"\"\n",
    "        device = 'cuda:{}'.format(gpu_ids[0]) if len(gpu_ids) > 0 else 'cpu'\n",
    "        pretrained_dict = torch.load(ckpt_path, map_location=device)['model_state']\n",
    "        model_dict = self.state_dict()\n",
    "\n",
    "        # Filter out unnecessary keys\n",
    "        pretrained_dict = {k[len('module.'):]: v for k, v in pretrained_dict.items()}\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "\n",
    "        # Overwrite entries in the existing state dict\n",
    "        model_dict.update(pretrained_dict)\n",
    "\n",
    "        # Load the new state dict\n",
    "        self.load_state_dict(model_dict)\n",
    "\n",
    "    def fine_tuning_parameters(self, fine_tuning_boundary, fine_tuning_lr=0.0):\n",
    "        \"\"\"Get parameters for fine-tuning the model.\n",
    "        Args:\n",
    "            fine_tuning_boundary: Name of first layer after the fine-tuning layers.\n",
    "            fine_tuning_lr: Learning rate to apply to fine-tuning layers (all layers before `boundary_layer`).\n",
    "        Returns:\n",
    "            List of dicts that can be passed to an optimizer.\n",
    "        \"\"\"\n",
    "\n",
    "        def gen_params(boundary_layer_name, fine_tuning):\n",
    "            \"\"\"Generate parameters, if fine_tuning generate the params before boundary_layer_name.\n",
    "            If unfrozen, generate the params at boundary_layer_name and beyond.\"\"\"\n",
    "            saw_boundary_layer = False\n",
    "            for name, param in self.named_parameters():\n",
    "                if name.startswith(boundary_layer_name):\n",
    "                    saw_boundary_layer = True\n",
    "\n",
    "                if saw_boundary_layer and fine_tuning:\n",
    "                    return\n",
    "                elif not saw_boundary_layer and not fine_tuning:\n",
    "                    continue\n",
    "                else:\n",
    "                    yield param\n",
    "\n",
    "        # Fine-tune the network's layers from encoder.2 onwards\n",
    "        optimizer_parameters = [{'params': gen_params(fine_tuning_boundary, fine_tuning=True), 'lr': fine_tuning_lr},\n",
    "                                {'params': gen_params(fine_tuning_boundary, fine_tuning=False)}]\n",
    "\n",
    "        # Debugging info\n",
    "        util.print_err('Number of fine-tuning layers: {}'\n",
    "                       .format(sum(1 for _ in gen_params(fine_tuning_boundary, fine_tuning=True))))\n",
    "        util.print_err('Number of regular layers: {}'\n",
    "                       .format(sum(1 for _ in gen_params(fine_tuning_boundary, fine_tuning=False))))\n",
    "\n",
    "        return optimizer_parameters\n",
    "    \n",
    "def peNet(num_classes):\n",
    "    net = PENetClassifier(50, num_classes = 1)\n",
    "    net = nn.DataParallel(net)\n",
    "    net.load_state_dict(torch.load('../input/mymodels/penet.pth'))\n",
    "    net.module.classifier.fc = nn.Linear(2048, num_classes)\n",
    "    return(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_eval_tab(model_name, eval_tab, tij):\n",
    "    dataset = PE_dataset_pipeline(eval_tab, tij)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = 4, num_workers = 2)\n",
    "    #load model\n",
    "    if model_name == 'chronic_net':\n",
    "        net = peNet(3)\n",
    "        net.load_state_dict(torch.load('../input/mymodels/best_chronic.pth'))\n",
    "        net = net.eval().cuda()\n",
    "    else:\n",
    "        net = peNet(2)\n",
    "        net = models[model_name](net)\n",
    "    #fill table\n",
    "    for i, (inpt, index) in tqdm(enumerate(dataloader)):\n",
    "        outpt = net(inpt)\n",
    "        for j, idx in enumerate(index):\n",
    "            if model_name == 'chronic_net':\n",
    "                eval_tab['negative_chronic'][idx.item()] = outpt[j][0].item()\n",
    "                eval_tab['chronic'][idx.item()] = outpt[j][1].item()\n",
    "                eval_tab['acute'][idx.item()] = outpt[j][2].item()\n",
    "            else:\n",
    "                eval_tab[C[model_name][0]][idx.item()] = outpt[j][0].item()\n",
    "                eval_tab[C[model_name][1]][idx.item()] = outpt[j][1].item()\n",
    "        outpt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_eval_tab2(eval_tab, tij):\n",
    "    dataset = PE_dataset_pipeline(eval_tab, tij)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = 4, num_workers = 2)\n",
    "    \n",
    "    #fill table\n",
    "    for i, (inpt, index) in tqdm(enumerate(dataloader)):\n",
    "        for model_name in ['big_detect_net', 'right_det_net', 'left_net', 'central_net', 'chronic_net']:\n",
    "            #load model\n",
    "            if model_name == 'chronic_net':\n",
    "                net = peNet(3)\n",
    "                net.load_state_dict(torch.load('../input/mymodels/best_chronic.pth'))\n",
    "                net = net.eval().cuda()\n",
    "            else:\n",
    "                net = peNet(2)\n",
    "                net = models[model_name](net)\n",
    "            outpt = net(inpt)\n",
    "            for j, idx in enumerate(index):\n",
    "                if model_name == 'chronic_net':\n",
    "                    eval_tab['negative_chronic'][idx.item()] = outpt[j][0].item()\n",
    "                    eval_tab['chronic'][idx.item()] = outpt[j][1].item()\n",
    "                    eval_tab['acute'][idx.item()] = outpt[j][2].item()\n",
    "                else:\n",
    "                    eval_tab[C[model_name][0]][idx.item()] = outpt[j][0].item()\n",
    "                    eval_tab[C[model_name][1]][idx.item()] = outpt[j][1].item()\n",
    "            outpt = None\n",
    "            net = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_eval_tab2(eval_tab, tij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill_eval_tab('chronic_net', eval_tab, tij)\n",
    "#fill_eval_tab('big_detect_net', eval_tab, tij)\n",
    "#fill_eval_tab('right_det_net', eval_tab, tij)\n",
    "#fill_eval_tab('left_net', eval_tab, tij)\n",
    "#fill_eval_tab('central_net', eval_tab, tij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PE_dataset_pipeline(torch.utils.data.Dataset):\n",
    "    def __init__(self, Table, eval_tab, window = 48):\n",
    "        self.slices = list(eval_tab['Exam'].unique())\n",
    "        self.window = window\n",
    "        self.Table = Table\n",
    "        self.eval_tab = eval_tab\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        mini_batch = self.eval_tab[self.eval_tab.Exam == self.slices[index]].reset_index().drop(['index'], axis = 1)\n",
    "        Study = mini_batch['Exam'][0]\n",
    "        temp = self.Table[self.Table.StudyInstanceUID == Study].reset_index().drop(['index'], axis = 1)\n",
    "        \n",
    "        #input construction\n",
    "        Input = torch.zeros(7*4)\n",
    "        Softner = nn.Softmax(dim = 0)\n",
    "        for i in mini_batch.index:\n",
    "            Input[i*7] = Softner(torch.Tensor([mini_batch['negative_detect'][i], mini_batch['positive_detect'][i]]))[1]\n",
    "            Input[i*7 + 1] = float(mini_batch['right_detect'][i])\n",
    "            Input[i*7 + 2] = float(mini_batch['right'][i])\n",
    "            Input[i*7 + 3] = Softner(torch.Tensor([mini_batch['negative_left'][i], mini_batch['positive_left'][i]]))[1]\n",
    "            Input[i*7 + 4] = Softner(torch.Tensor([mini_batch['negative_central'][i], mini_batch['positive_central'][i]]))[1]\n",
    "            Input[i*7 + 5] = Softner(torch.Tensor([mini_batch['negative_chronic'][i], mini_batch['chronic'][i], mini_batch['acute'][i]]))[1]\n",
    "            Input[i*7 + 6] = Softner(torch.Tensor([mini_batch['negative_chronic'][i], mini_batch['chronic'][i], mini_batch['acute'][i]]))[2]\n",
    "        return(Input, self.Table[self.Table.StudyInstanceUID == Study].index[0])\n",
    "    def __len__(self):\n",
    "        return(len(self.slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IntegNet, self).__init__()\n",
    "        self.dropout_rate = 0.5878\n",
    "        fc2_input_dim = 804\n",
    "        fc3_input_dim = 670\n",
    "        self.fc1 = nn.Linear(4*7, fc2_input_dim)\n",
    "        self.fc2 = nn.Linear(fc2_input_dim, fc3_input_dim)\n",
    "        self.fco = nn.Linear(fc3_input_dim, fc3_input_dim)\n",
    "        self.fc3 = nn.Linear(fc3_input_dim, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p = self.dropout_rate, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p = self.dropout_rate, training=self.training)\n",
    "        x = F.relu(self.fco(x))\n",
    "        x = F.dropout(x, p = self.dropout_rate, training=self.training)\n",
    "        x = self.fc3(x)\n",
    "        return x.clamp(min = 0, max = 1)\n",
    "\n",
    "# Generate the model.\n",
    "net = IntegNet()\n",
    "net.load_state_dict(torch.load('../input/mymodels/best_Integnet.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pe_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, Table, augment = True):\n",
    "        self.images = list(Table.index)\n",
    "        self.Table = Table\n",
    "        self.augmented = augment\n",
    "    def __getitem__(self, index):\n",
    "        image = read_image([self.Table['path'][self.images[index]]])\n",
    "        return(image, self.images[index])\n",
    "    def __len__(self):\n",
    "        return(len(self.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resnet50(num_classes, pretrained = True):\n",
    "    net = torchvision.models.resnet50(pretrained=pretrained, progress=True)\n",
    "    out_size = net.fc.in_features\n",
    "    net.fc = nn.Linear(out_size, num_classes)\n",
    "    return(net)\n",
    "def Resnet152(num_classes, pretrained = True):\n",
    "    net = torchvision.models.resnet152(pretrained=False, progress=True)\n",
    "    out_size = net.fc.in_features\n",
    "    net.fc = nn.Linear(out_size, num_classes)\n",
    "    return(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Submit(Exam_net, detect_net, eval_tab, tij, df):\n",
    "    dataset = PE_dataset_pipeline(tij, eval_tab)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = 1, num_workers = 2)\n",
    "    \n",
    "    sub = pd.read_csv('./submission.csv')\n",
    "    Elements = set(list(sub['id'][i].split('_')[0] for i in sub.index))\n",
    "    \n",
    "    Exam_net = Exam_net.eval().cuda()\n",
    "    for i, (Input, idx) in tqdm(enumerate(dataloader)):\n",
    "        Exam = tij['StudyInstanceUID'][idx[0].item()]\n",
    "        if Exam in Elements:\n",
    "            continue\n",
    "        outpt = Exam_net(Input[0].cuda())\n",
    "        temp = pd.DataFrame([[Exam+'_indeterminate', outpt[0].item()],\n",
    "                             [Exam+'_negative_exam_for_pe', outpt[1].item()],\n",
    "                             [Exam+'_central_pe', outpt[2].item()],\n",
    "                             [Exam+'_rightsided_pe', outpt[2].item()],\n",
    "                             [Exam+'_chronic_pe', outpt[3].item()],\n",
    "                             [Exam+'_acute_and_chronic_pe', outpt[4].item()],\n",
    "                             [Exam+'_rv_lv_ratio_gte_1', outpt[5].item()],\n",
    "                             [Exam+'_rv_lv_ratio_lt_1', outpt[6].item()]], columns = sub.columns)\n",
    "        sub = pd.concat([sub, temp])\n",
    "    dataset = pe_dataset(df)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = 15, num_workers = 2)\n",
    "    detect_net = detect_net.cuda().eval()\n",
    "    Softner = nn.Softmax()\n",
    "    for i, (Input, idx) in tqdm(enumerate(dataloader)):\n",
    "        outpt = detect_net(Input.cuda())\n",
    "        #print(output)\n",
    "        for i, index in enumerate(idx):\n",
    "            SOP = df['SOPInstanceUID'][index.item()]\n",
    "            if SOP in Elements:\n",
    "                continue\n",
    "            pred = Softner(outpt[i])[1].item()\n",
    "            temp = pd.DataFrame([[SOP, pred]], columns = sub.columns)\n",
    "            sub = pd.concat([sub, temp])\n",
    "    sub = sub[['id', 'label']]\n",
    "    sub.to_csv('./submission2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tij = pd.read_csv('../input/submission/test_exams.csv')\n",
    "#eval_tab = pd.read_csv('../input/submission/test_eval_tab.csv')\n",
    "detect_net = Resnet152(2)\n",
    "detect_net.load_state_dict(torch.load('../input/mymodels/best_detection.pth'))\n",
    "Submit(net, detect_net, eval_tab, tij, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
