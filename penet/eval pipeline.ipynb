{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import time\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from tqdm.notebook import *\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.43216, 0.394666, 0.37645],\n",
    "                            std=[0.22803, 0.22145, 0.216989])\n",
    "])\n",
    "trans1 = transforms.ToPILImage()\n",
    "\n",
    "from evaluation import *\n",
    "from complementary import *\n",
    "from Myutils import *\n",
    "from training_engine import *\n",
    "import optuna\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv('/media/aous/Samsung_T5/mtrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2368"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab[tab.negative_exam_for_pe == 0]['StudyInstanceUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7279"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab['StudyInstanceUID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resnet50(num_classes):\n",
    "    net = torchvision.models.resnet50(pretrained=True, progress=True)\n",
    "    out_size = net.fc.in_features\n",
    "    net.fc = nn.Linear(out_size, num_classes)\n",
    "    return(net)\n",
    "def Resnet152(num_classes):\n",
    "    net = torchvision.models.resnet152(pretrained=True, progress=True)\n",
    "    out_size = net.fc.in_features\n",
    "    net.fc = nn.Linear(out_size, num_classes)\n",
    "    return(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_batch(inpt_slices, outpt_size, size, augment):\n",
    "    inpt_slices.sort_values(['path'], inplace = True)\n",
    "    transform = transforms.Compose([\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize(mean=[0.43216, 0.394666, 0.37645],\n",
    "                                        std=[0.22803, 0.22145, 0.216989])\n",
    "                ])\n",
    "    outpt = torch.zeros((3, outpt_size, size[0], size[1]))\n",
    "    rot = (np.random.random()*2-1)*15\n",
    "    c = int((np.random.random()*2-1)*size[0]*0.15)\n",
    "    f = int((np.random.random()*2-1)*size[1]*0.15)\n",
    "    for i, idx in enumerate(inpt_slices.index):\n",
    "        im = Image.open(inpt_slices['path'][idx])\n",
    "        if augment:\n",
    "            im = im.rotate(rot, translate = (c,f))\n",
    "        im_vect = transform(im)\n",
    "        outpt[0][i] = im_vect[0]\n",
    "        outpt[1][i] = im_vect[1]\n",
    "        outpt[2][i] = im_vect[2]\n",
    "    return(outpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_resolution_CT(inpt_exam, outpt_size):\n",
    "    if len(inpt_exam) < outpt_size:\n",
    "        return(inpt_exam)\n",
    "    result = pd.DataFrame(columns = inpt_exam.columns)\n",
    "    temp = inpt_exam.reset_index().drop(['index'], axis = 1)\n",
    "    fact = int((len(inpt_exam)*10/outpt_size))\n",
    "    rm_count = fact - 10\n",
    "    #remove rm_count element from every fact batch\n",
    "    step = int(len(inpt_exam)/fact)\n",
    "    for i in range(step):\n",
    "        batch_t = temp[temp.index <= (i + 1)*fact]\n",
    "        batch = batch_t[batch_t.index > i*fact]\n",
    "        #rm_batch = batch[batch.pe_present_on_image == 0]\n",
    "        rm_batch = batch\n",
    "        if len(rm_batch) >= rm_count:\n",
    "            rm_idx = random.sample(list(rm_batch.index), rm_count)\n",
    "            batch.drop(rm_idx, axis = 0, inplace = True)\n",
    "            #print(rm_idx)\n",
    "        else:\n",
    "            batch.drop(rm_batch.index, axis = 0, inplace = True)\n",
    "            rm_idx = random.sample(list(batch.index), rm_count - len(rm_batch))\n",
    "            batch.drop(rm_idx, axis = 0, inplace = True)\n",
    "            #print(rm_idx)\n",
    "        result = pd.concat([result, batch]).reset_index().drop(['index'], axis = 1)\n",
    "    if len(result) == outpt_size -1:\n",
    "        result = pd.concat([result, result[len(result)-1:]]).reset_index().drop(['index'], axis = 1)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_slices(inpt_exam, window_size):\n",
    "    temp = inpt_exam.copy().reset_index().drop(['index'], axis=1)\n",
    "    temp['slice'] = inpt_exam['SOPInstanceUID']\n",
    "    step_num = int(len(inpt_exam)/window_size)\n",
    "    idx = 0\n",
    "    for i in range(step_num):\n",
    "        instance = temp['SOPInstanceUID'][i*window_size]\n",
    "        for j in range(window_size):\n",
    "            idx = i*window_size + j\n",
    "            temp['slice'][idx] = instance\n",
    "    if idx < len(inpt_exam)-1:\n",
    "        idx += 1\n",
    "        instance = temp['SOPInstanceUID'][idx]\n",
    "        temp['slice'][idx] = instance\n",
    "        for j in range(len(inpt_exam) - idx):\n",
    "            idx += 1\n",
    "            temp['slice'][idx] = instance\n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_3D(table, max_resol, window_size):\n",
    "    Exams = list(table['StudyInstanceUID'].unique())\n",
    "    #reduce resolution\n",
    "    l_res = pd.DataFrame(columns = table.columns)\n",
    "    l_res['slice'] = l_res['SOPInstanceUID']\n",
    "    for i, Exam in tqdm(enumerate(Exams)):\n",
    "        temp = table[table.StudyInstanceUID == Exam]\n",
    "        temp = reduce_resolution_CT(temp, max_resol)\n",
    "        #distinguish slices\n",
    "        temp = distinct_slices(temp, window_size)\n",
    "        l_res = pd.concat([l_res, temp])\n",
    "    l_res = l_res.reset_index().drop(['index'], axis = 1)\n",
    "    return(l_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492dff54e1784ebdb0df095f6b3d5086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aous/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tab = pd.read_csv('/media/aous/Samsung_T5/mtrain.csv')\n",
    "repart = list(tab['StudyInstanceUID'].unique())\n",
    "test_exams = repart[:1000]\n",
    "train_exams = repart[1000:]\n",
    "traindf = tab[tab['StudyInstanceUID'].isin(train_exams)]\n",
    "testdf = tab[tab['StudyInstanceUID'].isin(test_exams)]\n",
    "tij = table_3D(testdf, max_resol = 192, window_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tij.to_csv('mtest_192_48.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tij = pd.read_csv('mtest_192_48.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_detect(net):\n",
    "    big_detect_net = net\n",
    "    big_detect_net.load_state_dict(torch.load('best_Bigdetect.pth'))\n",
    "    big_detect_net = big_detect_net.eval()\n",
    "    #fscore 50% (good recall)\n",
    "    return(big_detect_net.cuda())\n",
    "def load_right(net):\n",
    "    right_det_net = net\n",
    "    right_det_net.load_state_dict(torch.load('PEright_45_49.pth'))\n",
    "    right_det_net = right_det_net.eval()\n",
    "    #detection: 45% + right: 49%\n",
    "    return(right_det_net.cuda())\n",
    "def load_left(net):\n",
    "    left_net = net\n",
    "    left_net.load_state_dict(torch.load('best_left.pth'))\n",
    "    left_net = left_net.eval()\n",
    "    #fscore 48% acc 91%\n",
    "    return(left_net.cuda())\n",
    "def load_central(net):\n",
    "    central_net = net\n",
    "    central_net.load_state_dict(torch.load('best_central.pth'))\n",
    "    central_net = central_net.eval()\n",
    "    #fscore 57%\n",
    "    return(central_net.cuda())\n",
    "models = {'big_detect_net': load_detect, 'right_det_net': load_right,\n",
    "          'left_net': load_left, 'central_net': load_central}\n",
    "modelslist = ['big_detect_net', 'right_det_net', 'left_net', 'central_net']\n",
    "C = {'big_detect_net': ['negative_detect', 'positive_detect'], 'right_det_net' : ['right_detect', 'right'],\n",
    "    'left_net': ['negative_left', 'positive_left'], 'central_net': ['negative_central', 'positive_central']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_pipeline(tab):\n",
    "    eval_tab = pd.DataFrame(columns = ['Exam', 'slice', 'negative_detect', 'positive_detect', \n",
    "                                      'right_detect', 'right', 'negative_left', 'positive_left',\n",
    "                                      'negative_central', 'positive_central', 'negative_chronic','chronic',\n",
    "                                     'acute', 'qa_motion', 'qa_contrast', 'flow_artifact', 'true_filling_defect_not_pe'])\n",
    "    Exams = tab['StudyInstanceUID'].dropna().unique()\n",
    "    for i, exam in tqdm(enumerate(Exams)):\n",
    "        B1 = [0]*17\n",
    "        B2 = [0]*17\n",
    "        B3 = [0]*17\n",
    "        B4 = [0]*17\n",
    "        ex = tab[tab.StudyInstanceUID == exam].reset_index().drop(['index'], axis = 1)\n",
    "        slices = ex['slice'].dropna().unique()\n",
    "        B1[0] = exam\n",
    "        B2[0] = exam\n",
    "        B3[0] = exam\n",
    "        B4[0] = exam\n",
    "        B1[1] = slices[0]\n",
    "        B2[1] = slices[1]\n",
    "        try:\n",
    "            B3[1] = slices[2]\n",
    "        except:\n",
    "            B3[1] = 'noslice'\n",
    "        try:\n",
    "            B4[1] = slices[3]\n",
    "        except:\n",
    "            B4[1] = 'noslice'\n",
    "        B1[13] = ex['qa_motion'][0]\n",
    "        B1[14] = ex['qa_contrast'][0]\n",
    "        B1[15] = ex['flow_artifact'][0]\n",
    "        B1[16] = ex['true_filling_defect_not_pe'][0]\n",
    "        B2[13] = ex['qa_motion'][0]\n",
    "        B2[14] = ex['qa_contrast'][0]\n",
    "        B3[15] = ex['flow_artifact'][0]\n",
    "        B4[16] = ex['true_filling_defect_not_pe'][0]\n",
    "        B3[13] = ex['qa_motion'][0]\n",
    "        B3[14] = ex['qa_contrast'][0]\n",
    "        B3[15] = ex['flow_artifact'][0]\n",
    "        B3[16] = ex['true_filling_defect_not_pe'][0]\n",
    "        B4[13] = ex['qa_motion'][0]\n",
    "        B4[14] = ex['qa_contrast'][0]\n",
    "        B4[15] = ex['flow_artifact'][0]\n",
    "        B4[16] = ex['true_filling_defect_not_pe'][0]\n",
    "        \n",
    "        B1 = pd.DataFrame([B1], columns= eval_tab.columns)\n",
    "        B2 = pd.DataFrame([B2], columns= eval_tab.columns)\n",
    "        B3 = pd.DataFrame([B3], columns= eval_tab.columns)\n",
    "        B4 = pd.DataFrame([B4], columns= eval_tab.columns)\n",
    "        \n",
    "        eval_tab = pd.concat([eval_tab, B1, B2, B3, B4])\n",
    "    return(eval_tab.reset_index().drop(['index'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a385d5cdfff1437e903e9fdfae6e25ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_tab = empty_pipeline(tij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tab.to_csv('test_eval_tab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tab = pd.read_csv('test_eval_tab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in eval_tab.columns[3:14]:\n",
    "    eval_tab[col] = pd.to_numeric(eval_tab[col], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_batch(inpt_slices, outpt_size, size, augment):\n",
    "    inpt_slices.sort_values(['path'], inplace = True)\n",
    "    transform = transforms.Compose([\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize(mean=[0.43216, 0.394666, 0.37645],\n",
    "                                        std=[0.22803, 0.22145, 0.216989])\n",
    "                ])\n",
    "    outpt = torch.zeros((3, outpt_size, size[0], size[1]))\n",
    "    rot = (np.random.random()*2-1)*15\n",
    "    c = int((np.random.random()*2-1)*size[0]*0.15)\n",
    "    f = int((np.random.random()*2-1)*size[1]*0.15)\n",
    "    for i, idx in enumerate(inpt_slices.index):\n",
    "        im = Image.open(inpt_slices['path'][idx])\n",
    "        if augment:\n",
    "            im = im.rotate(rot, translate = (c,f))\n",
    "        im_vect = transform(im)\n",
    "        outpt[0][i] = im_vect[0]\n",
    "        outpt[1][i] = im_vect[1]\n",
    "        outpt[2][i] = im_vect[2]\n",
    "    return(outpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PE_dataset_pipeline(torch.utils.data.Dataset):\n",
    "    def __init__(self, eval_tab, tab, window = 48):\n",
    "        self.slices = list(eval_tab['slice'].unique())\n",
    "        self.slices.remove('noslice')\n",
    "        self.window = window\n",
    "        self.Table = eval_tab\n",
    "        self.tab = tab\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        mini_batch = self.Table[self.Table.slice == self.slices[index]]\n",
    "        mb = self.tab[self.tab.slice == self.slices[index]]\n",
    "        Input = form_batch(mb, self.window, (256, 256), False)\n",
    "        return([Input, mini_batch.index[0]])\n",
    "    def __len__(self):\n",
    "        return(len(self.slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_eval_tab(model_name, eval_tab, tij):\n",
    "    dataset = PE_dataset_pipeline(eval_tab, tij)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = 4, num_workers = 2)\n",
    "    #load model\n",
    "    if model_name == 'chronic_net':\n",
    "        net = peNet(3)\n",
    "        net.load_state_dict(torch.load('best_chronic.pth'))\n",
    "        net = net.eval().cuda()\n",
    "    else:\n",
    "        net = peNet(2)\n",
    "        net = models[model_name](net)\n",
    "    #fill table\n",
    "    for i, (inpt, index) in tqdm(enumerate(dataloader)):\n",
    "        outpt = net(inpt)\n",
    "        for j, idx in enumerate(index):\n",
    "            if model_name == 'chronic_net':\n",
    "                eval_tab['negative_chronic'][idx.item()] = outpt[j][0].item()\n",
    "                eval_tab['chronic'][idx.item()] = outpt[j][1].item()\n",
    "                eval_tab['acute'][idx.item()] = outpt[j][2].item()\n",
    "            else:\n",
    "                eval_tab[C[model_name][0]][idx.item()] = outpt[j][0].item()\n",
    "                eval_tab[C[model_name][1]][idx.item()] = outpt[j][1].item()\n",
    "        outpt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = {'big_detect_net': ['negative_detect', 'positive_detect'], 'right_det_net' : ['right_detect', 'right'],\n",
    "    'left_net': ['negative_left', 'positive_left'], 'central_net': ['negative_central', 'positive_central']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f7b1dac71847fd933c291af54d45f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ed307d9dcf42d5be44aad545c13693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ce108ae2f24c1fb10109768fbfb444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aous/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "fill_eval_tab('chronic_net', eval_tab, tij)\n",
    "fill_eval_tab('big_detect_net', eval_tab, tij)\n",
    "fill_eval_tab('right_det_net', eval_tab, tij)\n",
    "fill_eval_tab('left_net', eval_tab, tij)\n",
    "fill_eval_tab('central_net', eval_tab, tij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tab.to_csv('eval_tab_filled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PE_dataset_pipeline(torch.utils.data.Dataset):\n",
    "    def __init__(self, Table, eval_tab, window = 48):\n",
    "        self.slices = list(eval_tab['slice'].unique())\n",
    "        self.window = window\n",
    "        self.Table = Table\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        mini_batch = self.Table[self.Table.slice == self.slices[index]].reset_index().drop(['index'], axis = 1)\n",
    "        Study = mini_batch['Exam'][0]\n",
    "        temp = self.Table[self.Table.StudyInstanceUID == Study]\n",
    "        Input = form_batch(mini_batch, self.window, (256, 256), self.augmented)\n",
    "        \n",
    "        Target = torch.zeros(9)\n",
    "        pe_num = len(mini_batch[mini_batch.pe_present_on_image == 1])\n",
    "        Target[0] = mini_batch['indeterminate'][0]\n",
    "        Target[1] = mini_batch['negative_exam_for_pe'][0]\n",
    "        Target[2] = mini_batch['central_pe'][0]\n",
    "        Target[3] = mini_batch['rightsided_pe'][0]\n",
    "        Target[4] = mini_batch['leftsided_pe'][0]\n",
    "        Target[5] = mini_batch['chronic_pe'][0]\n",
    "        Target[6] = mini_batch['acute_and_chronic_pe'][0]\n",
    "        Target[7] = mini_batch['rv_lv_ratio_gte_1'][0]\n",
    "        Target[8] = mini_batch['rv_lv_ratio_lt_1'][0]\n",
    "        return([Input, Target])\n",
    "    def __len__(self):\n",
    "        return(len(self.slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(tab):\n",
    "    eval_tab = pd.DataFrame(columns = ['Exam', 'negative_detect', 'positive_detect', \n",
    "                                      'right_detect', 'right', 'negative_left', 'positive_left',\n",
    "                                      'negative_central', 'positive_central', 'negative_chronic','chronic',\n",
    "                                     'acute', 'qa_motion', 'qa_contrast', 'flow_artifact', 'true_filling_defect_not_pe'])\n",
    "    Exams = tab['StudyInstanceUID'].dropna().unique()\n",
    "    #non chronic: 86% chronic: 15% acute: 26%\n",
    "    for i, exam in tqdm(enumerate(Exams)):\n",
    "        B1 = [0]*16\n",
    "        B2 = [0]*16\n",
    "        B3 = [0]*16\n",
    "        B4 = [0]*16\n",
    "        ex = tab[tab.StudyInstanceUID == exam].reset_index().drop(['index'], axis = 1)\n",
    "        slices = ex['slice'].dropna().unique()\n",
    "        B1[0] = exam\n",
    "        B2[0] = exam\n",
    "        B3[0] = exam\n",
    "        B4[0] = exam\n",
    "        inpt = torch.zeros((4, 3, 48, 256, 256)).cuda()\n",
    "        for i, sl in enumerate(slices[:4]):\n",
    "            batch = form_batch(tab[tab.slice == sl], 48, (256,256), False)\n",
    "            inpt[i] = batch\n",
    "        for i, model in enumerate(modelslist):\n",
    "            net = peNet(2)\n",
    "            net = models[model](net)\n",
    "            outpt = net(inpt)\n",
    "            B1[2*i+1] = outpt[0][0].item()\n",
    "            B1[2*i+2] = outpt[0][1].item()\n",
    "            B2[2*i+1] = outpt[1][0].item()\n",
    "            B2[2*i+2] = outpt[1][1].item()\n",
    "            B3[2*i+1] = outpt[2][0].item()\n",
    "            B3[2*i+2] = outpt[2][1].item()\n",
    "            B4[2*i+1] = outpt[3][0].item()\n",
    "            B4[2*i+2] = outpt[3][1].item()\n",
    "            outpt = None\n",
    "            net = None\n",
    "            batch = None\n",
    "        net = peNet(3)\n",
    "        net.load_state_dict(torch.load('best_chronic.pth'))\n",
    "        net = net.eval().cuda()\n",
    "        outpt = net(inpt)\n",
    "        B1[9] = outpt[0][0].item()\n",
    "        B1[10] = outpt[0][1].item()\n",
    "        B1[11] = outpt[0][2].item()\n",
    "        B1[12] = ex['qa_motion'][0]\n",
    "        B1[13] = ex['qa_contrast'][0]\n",
    "        B1[14] = ex['flow_artifact'][0]\n",
    "        B1[15] = ex['true_filling_defect_not_pe'][0]\n",
    "        B2[9] = outpt[1][0].item()\n",
    "        B2[10] = outpt[1][1].item()\n",
    "        B2[11] = outpt[1][2].item()\n",
    "        B2[12] = ex['qa_motion'][0]\n",
    "        B2[13] = ex['qa_contrast'][0]\n",
    "        B3[14] = ex['flow_artifact'][0]\n",
    "        B4[15] = ex['true_filling_defect_not_pe'][0]\n",
    "        B3[9] = outpt[2][0].item()\n",
    "        B3[10] = outpt[2][1].item()\n",
    "        B3[11] = outpt[2][2].item()\n",
    "        B3[12] = ex['qa_motion'][0]\n",
    "        B3[13] = ex['qa_contrast'][0]\n",
    "        B3[14] = ex['flow_artifact'][0]\n",
    "        B3[15] = ex['true_filling_defect_not_pe'][0]\n",
    "        B4[9] = outpt[3][0].item()\n",
    "        B4[10] = outpt[3][1].item()\n",
    "        B4[11] = outpt[3][2].item()\n",
    "        B4[12] = ex['qa_motion'][0]\n",
    "        B4[13] = ex['qa_contrast'][0]\n",
    "        B4[14] = ex['flow_artifact'][0]\n",
    "        B4[15] = ex['true_filling_defect_not_pe'][0]\n",
    "        outpt = None\n",
    "        net = None\n",
    "        batch = None\n",
    "        \n",
    "        B1 = pd.DataFrame([B1], columns= eval_tab.columns)\n",
    "        B2 = pd.DataFrame([B2], columns= eval_tab.columns)\n",
    "        B3 = pd.DataFrame([B3], columns= eval_tab.columns)\n",
    "        B4 = pd.DataFrame([B4], columns= eval_tab.columns)\n",
    "        \n",
    "        eval_tab = pd.concat([eval_tab, B1, B2, B3, B4])\n",
    "    return(eval_tab.reset_index().drop(['index'], axis = 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
